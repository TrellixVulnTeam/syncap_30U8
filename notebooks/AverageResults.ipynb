{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJECTIVES_COLORS_ANIMATE = {\"black_cat\", \"brown_dog\", \"white_horse\", \"black_bird\"}\n",
    "ADJECTIVES_COLORS_INANIMATE = {\"red_bus\", \"white_truck\", \"blue_bus\", \"white_boat\"}\n",
    "\n",
    "ADJECTIVES_SIZES_ANIMATE = {\"big_bird\", \"small_cat\", \"big_cat\", \"small_dog\"}\n",
    "ADJECTIVES_SIZES_INANIMATE = {\"small_plane\", \"big_plane\", \"small_table\", \"big_truck\"}\n",
    "\n",
    "VERBS_TRANSITIVE = {\"eat_man\", \"ride_woman\", \"hold_child\", \"eat_horse\"}\n",
    "VERBS_INTRANSITIVE = {\"lie_woman\", \"fly_bird\", \"stand_bird\", \"stand_child\"}\n",
    "\n",
    "all_pairs = ADJECTIVES_COLORS_ANIMATE.union(ADJECTIVES_COLORS_INANIMATE).union(ADJECTIVES_SIZES_ANIMATE)\\\n",
    "                                     .union(ADJECTIVES_SIZES_INANIMATE).union(VERBS_TRANSITIVE).union(VERBS_INTRANSITIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_coco_metrics(model_dir, split='test', beam=5, rr=False):\n",
    "    if rr:\n",
    "        fn = 'coco.re_ranking.beam_%d.%s' % (beam, split)\n",
    "    else:\n",
    "        fn = 'coco.beam_%d.%s' % (beam, split)\n",
    "    with open(os.path.join(model_dir, fn)) as f:\n",
    "        lines = f.readlines()\n",
    "    results = dict()\n",
    "    for line in lines:\n",
    "        m, s = line.split(': ')\n",
    "        results[m] = 100*float(s)\n",
    "    return results\n",
    "\n",
    "def avg_coco_metrics(metrics_dicts):\n",
    "    count = len(metrics_dicts)\n",
    "    results = defaultdict(int)\n",
    "    for ix, d in metrics_dicts.items():\n",
    "        for m, s in d.items():\n",
    "            results[m] += s\n",
    "    for m in results:\n",
    "        results[m] /= count\n",
    "    return results\n",
    "\n",
    "def read_pair_recalls(mdir, concept_pairs, at=5, split='test', beam=5, rr=False):\n",
    "    if rr:\n",
    "        fn = 'recall_%d.%s.re_ranking.beam_%d.%s' % (at, '%s', beam, split)\n",
    "    else:\n",
    "        fn = 'recall_%d.%s.beam_%d.%s' % (at, '%s', beam, split)\n",
    "    basefile = os.path.join(mdir, fn)\n",
    "    results = dict()\n",
    "    for pair in concept_pairs:\n",
    "        fn = basefile % pair\n",
    "        if os.path.isfile(fn):\n",
    "            with open(fn) as f:\n",
    "                recall_score = json.load(f)\n",
    "            results[pair] = recall_score\n",
    "    return results\n",
    "\n",
    "def average_recall(recall_scores, min_importance=1):\n",
    "    pair_recalls_summed = 0\n",
    "    length = 0\n",
    "    for i, pair in enumerate(recall_scores.keys()):\n",
    "        average_pair_recall = np.sum(list(recall_scores[pair][\"true_positives\"].values())[min_importance - 1:]) / \\\n",
    "                              np.sum(list(recall_scores[pair][\"numbers\"].values())[min_importance - 1:])\n",
    "        if not np.isnan(average_pair_recall):\n",
    "            pair_recalls_summed += average_pair_recall\n",
    "            length += 1\n",
    "    recall = 100 * pair_recalls_summed / length\n",
    "    return recall\n",
    "\n",
    "def agg_bertscores(model_fns):\n",
    "    all_scores = []\n",
    "    for fn in model_fns:        \n",
    "        with open(fn) as f:\n",
    "            scores = [float(l.split()[-1]) for l in f.readlines()[5:]]\n",
    "        all_scores += scores\n",
    "    bertscore = 100 * np.mean(all_scores)\n",
    "    return bertscore\n",
    "\n",
    "def get_scores(model2dirs, split='test', beam=100, recall_at=5):\n",
    "    # Recall\n",
    "    model2recalls = {m: {i+1: read_pair_recalls(os.path.join(mdir, 'results'), all_pairs, recall_at, split, beam, rr=('+rr' in m)) \n",
    "                         for i, mdir in enumerate(mdirs)} \n",
    "                     for m, mdirs in model2dirs.items()}\n",
    "    model2pair2metrics = dict()\n",
    "    for model, values in model2recalls.items():\n",
    "        model2pair2metrics[model] = dict()\n",
    "        for val in values.values():\n",
    "            for pair, metrics in val.items():\n",
    "                model2pair2metrics[model][pair] = metrics\n",
    "    model2avg_recall = {model: average_recall(pair2metrics) for model, pair2metrics in model2pair2metrics.items()}\n",
    "    # COCO metrics\n",
    "    model2coco_metrics = {m: {i+1: read_coco_metrics(os.path.join(mdir, 'results'), split, beam=beam, rr=('+rr' in m)) \n",
    "                              for i, mdir in enumerate(mdirs)} \n",
    "                          for m, mdirs in model2dirs.items()}\n",
    "    model2avg_coco_metrics = {model: avg_coco_metrics(metrics) for model, metrics in model2coco_metrics.items()}\n",
    "    # BERTScore\n",
    "    model2bs = {m: agg_bertscores([os.path.join(mdir, 'bertscore/%s.out' % split) for mdir in mdirs]) for m, mdirs in model2dirs.items()}\n",
    "    return model2avg_recall, model2avg_coco_metrics, model2bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_print(model2avg_recall, model2avg_coco_metrics, model2bs):\n",
    "    print('\\\\textbf{Model} & \\\\textbf{R@5} & \\\\textbf{M} & \\\\textbf{S} & \\\\textbf{C} & \\\\textbf{B} & \\\\textbf{BS} \\\\\\\\')\n",
    "    for model, score in model2avg_recall.items():\n",
    "        line = model.upper() + \" & %.1f \" % score\n",
    "        coco_scores = model2avg_coco_metrics[model]\n",
    "        for metric in ['METEOR', 'SPICE', 'CIDEr', 'Bleu_4']:\n",
    "            line += \"& %.1f \" % coco_scores[metric]\n",
    "        line += \"& %.1f \" % model2bs[model]\n",
    "        line += \"\\\\\\\\\"\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = 100\n",
    "recall_at = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax Awareness (with BUTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{Model} & \\textbf{R@5} & \\textbf{M} & \\textbf{S} & \\textbf{C} & \\textbf{B} & \\textbf{BS} \\\\\n",
      "BUTD & 9.5 & 25.2 & 18.6 & 92.7 & 32.3 & 41.7 \\\\\n",
      "BUTD+IDLE & 8.7 & 23.7 & 17.8 & 87.6 & 30.0 & 38.8 \\\\\n",
      "BUTD+CHUNK & 10.9 & 24.7 & 18.2 & 89.2 & 31.2 & 41.2 \\\\\n",
      "BUTD+POS & 9.5 & 24.1 & 17.5 & 86.1 & 30.1 & 40.7 \\\\\n",
      "BUTD+DEP & 11.1 & 24.6 & 17.8 & 89.7 & 30.8 & 41.0 \\\\\n",
      "BUTD+CCG & 10.6 & 24.5 & 18.0 & 88.4 & 30.4 & 41.0 \\\\\n"
     ]
    }
   ],
   "source": [
    "approach = 'seq'\n",
    "basedir = \"../experiments/\"\n",
    "model2dirs = {'butd': [basedir+'coco_heldout_%d/butd/' % d for d in range(1,4+1)],\n",
    "              'butd+idle': [basedir+'coco_heldout_%d_idle_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+chunk': [basedir+'coco_heldout_%d_chunk_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+pos': [basedir+'coco_heldout_%d_pos_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+dep': [basedir+'coco_heldout_%d_dep_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+ccg': [basedir+'coco_heldout_%d_ccg_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "             }\n",
    "\n",
    "model2avg_recall, model2avg_coco_metrics, model2bertscore = get_scores(model2dirs, split=split, beam=beam, recall_at=recall_at)\n",
    "latex_print(model2avg_recall, model2avg_coco_metrics, model2bertscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{Model} & \\textbf{R@5} & \\textbf{M} & \\textbf{S} & \\textbf{C} & \\textbf{B} & \\textbf{BS} \\\\\n",
      "BUTD & 9.5 & 25.2 & 18.6 & 92.7 & 32.3 & 41.7 \\\\\n",
      "BUTD+IDLE & 10.5 & 25.3 & 18.8 & 94.3 & 32.3 & 41.7 \\\\\n",
      "BUTD+CHUNK & 9.7 & 25.2 & 18.7 & 93.4 & 32.5 & 41.7 \\\\\n",
      "BUTD+POS & 11.8 & 25.4 & 18.8 & 94.4 & 32.7 & 41.7 \\\\\n",
      "BUTD+DEP & 10.8 & 25.2 & 18.7 & 93.0 & 31.9 & 41.6 \\\\\n",
      "BUTD+CCG & 10.5 & 25.4 & 19.0 & 94.6 & 32.7 & 41.9 \\\\\n"
     ]
    }
   ],
   "source": [
    "approach = 'inter'\n",
    "basedir = \"../experiments/\"\n",
    "model2dirs = {'butd': [basedir+'coco_heldout_%d/butd/' % d for d in range(1,4+1)],\n",
    "              'butd+idle': [basedir+'coco_heldout_%d_idle_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+chunk': [basedir+'coco_heldout_%d_chunk_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+pos': [basedir+'coco_heldout_%d_pos_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+dep': [basedir+'coco_heldout_%d_dep_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+ccg': [basedir+'coco_heldout_%d_ccg_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "             }\n",
    "\n",
    "model2avg_recall, model2avg_coco_metrics, model2bertscore = get_scores(model2dirs, split=split, beam=beam, recall_at=recall_at)\n",
    "latex_print(model2avg_recall, model2avg_coco_metrics, model2bertscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{Model} & \\textbf{R@5} & \\textbf{M} & \\textbf{S} & \\textbf{C} & \\textbf{B} & \\textbf{BS} \\\\\n",
      "BUTD & 9.5 & 25.2 & 18.6 & 92.7 & 32.3 & 41.7 \\\\\n",
      "BUTD+IDLE & 9.8 & 25.5 & 18.7 & 94.5 & 32.7 & 41.8 \\\\\n",
      "BUTD+CHUNK & 10.3 & 25.5 & 19.0 & 94.5 & 32.4 & 41.9 \\\\\n",
      "BUTD+POS & 10.3 & 25.4 & 18.8 & 93.8 & 32.6 & 41.8 \\\\\n",
      "BUTD+DEP & 11.4 & 25.5 & 18.9 & 93.9 & 32.7 & 41.9 \\\\\n",
      "BUTD+CCG & 10.8 & 25.7 & 19.0 & 95.6 & 32.7 & 42.0 \\\\\n"
     ]
    }
   ],
   "source": [
    "approach = 'multi'\n",
    "basedir = \"../experiments/\"\n",
    "model2dirs = {'butd': [basedir+'coco_heldout_%d/butd/' % d for d in range(1,4+1)],\n",
    "              'butd+idle': [basedir+'coco_heldout_%d_idle_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+chunk': [basedir+'coco_heldout_%d_chunk_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+pos': [basedir+'coco_heldout_%d_pos_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+dep': [basedir+'coco_heldout_%d_dep_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "              'butd+ccg': [basedir+'coco_heldout_%d_ccg_%s/butd/' % (d, approach) for d in range(1,4+1)],\n",
    "             }\n",
    "\n",
    "model2avg_recall, model2avg_coco_metrics, model2bertscore = get_scores(model2dirs, split=split, beam=beam, recall_at=recall_at)\n",
    "latex_print(model2avg_recall, model2avg_coco_metrics, model2bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results (standard & interleaved POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{Model} & \\textbf{R@5} & \\textbf{M} & \\textbf{S} & \\textbf{C} & \\textbf{B} & \\textbf{BS} \\\\\n",
      "BUTD & 9.5 & 25.2 & 18.6 & 92.7 & 32.3 & 41.7 \\\\\n",
      "BUTD+POS & 11.8 & 25.4 & 18.8 & 94.4 & 32.7 & 41.7 \\\\\n",
      "BUTR+RR & 15.0 & 26.2 & 19.9 & 88.6 & 28.9 & 41.8 \\\\\n",
      "BUTR+RR+POS & 12.0 & 25.7 & 19.4 & 85.4 & 27.4 & 41.4 \\\\\n",
      "BUTR_MEAN+RR+POS & 14.2 & 25.9 & 19.7 & 87.4 & 28.3 & 42.9 \\\\\n",
      "BUTR_WEIGHT+RR & 14.9 & 26.4 & 20.2 & 88.8 & 28.5 & 43.2 \\\\\n",
      "BUTR_WEIGHT+RR+POS & 16.4 & 26.4 & 20.0 & 89.8 & 29.1 & 43.1 \\\\\n",
      "M2 & 10.6 & 27.9 & 21.6 & 114.0 & 37.2 & 44.4 \\\\\n",
      "M2+POS & 13.2 & 28.0 & 21.7 & 113.8 & 35.4 & 44.9 \\\\\n"
     ]
    }
   ],
   "source": [
    "split = 'val'\n",
    "basedir = \"../experiments/\"\n",
    "model2dirs = {'butd': [basedir+'coco_heldout_%d/butd/' % d for d in range(1,4+1)],\n",
    "              'butd+pos': [basedir+'coco_heldout_%d_pos_inter/butd/' % d for d in range(1,4+1)],\n",
    "              'butr+rr': [basedir+'coco_heldout_%d/butr/' % d for d in range(1,4+1)],\n",
    "              'butr+rr+pos': [basedir+'coco_heldout_%d_pos_inter/butr/' % d for d in range(1,4+1)],\n",
    "              'butr_mean+rr+pos': [basedir+'coco_heldout_%d_pos_inter/butr_mean/' % d for d in range(1,4+1)],\n",
    "              'butr_weight+rr': [basedir+'coco_heldout_%d/butr_weight/' % d for d in range(1,4+1)],\n",
    "              'butr_weight+rr+pos': [basedir+'coco_heldout_%d_pos_inter/butr_weight/' % d for d in range(1,4+1)],\n",
    "              'm2': [basedir+'coco_heldout_%d/m2/' % d for d in range(1,4+1)],\n",
    "              'm2+pos': [basedir+'coco_heldout_%d_pos_inter/m2/' % d for d in range(1,4+1)],\n",
    "             }\n",
    "\n",
    "model2avg_recall, model2avg_coco_metrics, model2bertscore = get_scores(model2dirs, split=split, beam=beam, recall_at=recall_at)\n",
    "latex_print(model2avg_recall, model2avg_coco_metrics, model2bertscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{Model} & \\textbf{R@5} & \\textbf{M} & \\textbf{S} & \\textbf{C} & \\textbf{B} & \\textbf{BS} \\\\\n",
      "BUTD & 9.2 & 25.4 & 18.6 & 94.4 & 32.4 & 41.8 \\\\\n",
      "BUTD+POS & 11.1 & 25.4 & 18.7 & 96.3 & 32.9 & 41.8 \\\\\n",
      "BUTR+RR & 13.7 & 26.1 & 19.7 & 89.8 & 28.4 & 42.0 \\\\\n",
      "BUTR+RR+POS & 11.5 & 25.6 & 19.2 & 87.9 & 27.6 & 41.5 \\\\\n",
      "BUTR_MEAN+RR+POS & 13.4 & 25.9 & 19.7 & 88.9 & 27.9 & 43.0 \\\\\n",
      "BUTR_WEIGHT+RR & 13.5 & 26.4 & 20.1 & 91.0 & 28.6 & 43.3 \\\\\n",
      "BUTR_WEIGHT+RR+POS & 15.4 & 26.3 & 20.0 & 91.0 & 28.7 & 43.2 \\\\\n",
      "M2 & 10.1 & 27.8 & 21.5 & 115.7 & 36.5 & 44.5 \\\\\n",
      "M2+POS & 12.1 & 28.0 & 21.6 & 115.7 & 35.0 & 44.9 \\\\\n"
     ]
    }
   ],
   "source": [
    "split = 'test'\n",
    "basedir = \"../experiments/\"\n",
    "model2dirs = {'butd': [basedir+'coco_heldout_%d/butd/' % d for d in range(1,4+1)],\n",
    "              'butd+pos': [basedir+'coco_heldout_%d_pos_inter/butd/' % d for d in range(1,4+1)],\n",
    "              'butr+rr': [basedir+'coco_heldout_%d/butr/' % d for d in range(1,4+1)],\n",
    "              'butr+rr+pos': [basedir+'coco_heldout_%d_pos_inter/butr/' % d for d in range(1,4+1)],\n",
    "              'butr_mean+rr+pos': [basedir+'coco_heldout_%d_pos_inter/butr_mean/' % d for d in range(1,4+1)],\n",
    "              'butr_weight+rr': [basedir+'coco_heldout_%d/butr_weight/' % d for d in range(1,4+1)],\n",
    "              'butr_weight+rr+pos': [basedir+'coco_heldout_%d_pos_inter/butr_weight/' % d for d in range(1,4+1)],\n",
    "              'm2': [basedir+'coco_heldout_%d/m2/' % d for d in range(1,4+1)],\n",
    "              'm2+pos': [basedir+'coco_heldout_%d_pos_inter/m2/' % d for d in range(1,4+1)],\n",
    "             }\n",
    "\n",
    "model2avg_recall, model2avg_coco_metrics, model2bertscore = get_scores(model2dirs, split=split, beam=beam, recall_at=recall_at)\n",
    "latex_print(model2avg_recall, model2avg_coco_metrics, model2bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
